{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os, os.path\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import signal\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from model import Model\n",
    "import offline\n",
    "\n",
    "import tools\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main.py] Found 1 cuda devices available.\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Main pilot that can train or evaluate online or offline from a dataset.')\n",
    "  \n",
    "# ==========================\n",
    "#   Training Parameters\n",
    "# ==========================\n",
    "parser.add_argument(\"--testing\", action='store_true', help=\"In case we're only testing, the model is tested on the test.txt files and not trained.\")\n",
    "parser.add_argument(\"--learning_rate\", default=0.1, type=float, help=\"Start learning rate.\")\n",
    "parser.add_argument(\"--batch_size\",default=64,type=int,help=\"Define the size of minibatches.\")\n",
    "parser.add_argument(\"--clip\",default=1,type=float,help=\"Clip gradients to avoid 'nan' loss values.\")\n",
    "parser.add_argument(\"--max_episodes\",default=1000,type=int,help=\"The maximum number of episodes (~runs through all the training data.)\")\n",
    "parser.add_argument(\"--tensorboard\", action='store_true', help=\"Save logging in tensorboard.\")\n",
    "parser.add_argument(\"--create_scratch_checkpoint\", action='store_true', help=\"Dont train, just save checkpoint before starting and quit.\")\n",
    "\n",
    "# ==========================\n",
    "#   Lifelonglearning Parameters\n",
    "# ==========================\n",
    "parser.add_argument(\"--lifelonglearning\",action='store_true',help=\"In case there is a previous domain upon which the model was trained, use the lifelonglearning regularization to overcome forgetting.\")\n",
    "parser.add_argument(\"--update_importance_weights\",action='store_true',help=\"Update importance weights for all variables for this domain.\")\n",
    "parser.add_argument(\"--lll_weight\", default=1, type=float, help=\"Weight the lifelonglearning regularization term in the overall loss.\")\n",
    "parser.add_argument(\"--calculate_importance_weights\",action='store_true',help=\"Calculate the importance weights at the end of training and save them as pickled object.\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "#   Offline Parameters\n",
    "# ==========================\n",
    "parser.add_argument(\"--visualize_saliency_of_output\",action='store_true',help=\"Visualize saliency maps of the output.\")\n",
    "parser.add_argument(\"--visualize_deep_dream_of_output\",action='store_true',help=\"Visualize gradient ascent maps for different extreme controls.\")\n",
    "parser.add_argument(\"--visualize_activations\",action='store_true',help=\"Visualize activation.\")\n",
    "parser.add_argument(\"--visualize_control_activation_maps\",action='store_true',help=\"Visualize control activation map.\")\n",
    "parser.add_argument(\"--histogram_of_activations\",action='store_true',help=\"Summarize all activations in a histogram.\")\n",
    "parser.add_argument(\"--histogram_of_weights\",action='store_true',help=\"Summarize all weights in a histogram.\")\n",
    "\n",
    "# ===========================\n",
    "#   Utility Parameters\n",
    "# ===========================\n",
    "# Print output of ros verbose or not\n",
    "parser.add_argument(\"--load_config\", action='store_true',help=\"Load flags from the configuration file found in the checkpoint path.\")\n",
    "parser.add_argument(\"--verbose\", action='store_false', help=\"Print output of ros verbose or not.\")\n",
    "parser.add_argument(\"--summary_dir\", default='tensorflow/log/', type=str, help=\"Choose the directory to which tensorflow should save the summaries.\")\n",
    "parser.add_argument(\"-t\",\"--log_tag\", default='testing', type=str, help=\"Add log_tag to overcome overwriting of other log files.\")\n",
    "parser.add_argument(\"--device\", default='gpu', type=str, help= \"Choose to run on gpu or cpu: /cpu:0 or /gpu:0\")\n",
    "parser.add_argument(\"--random_seed\", default=123, type=int, help=\"Set the random seed to get similar examples.\")\n",
    "parser.add_argument(\"--owr\", action='store_true', help=\"Overwrite existing logfolder when it is not testing.\")\n",
    "parser.add_argument(\"--action_bound\", default=1.0, type=float, help= \"Define between what bounds the actions can go. Default: [-1:1].\")\n",
    "parser.add_argument(\"--action_dim\", default=1.0, type=float, help= \"Define the dimension of the actions: 1dimensional as it only turns in yaw.\")\n",
    "parser.add_argument(\"--real\", action='store_true', help=\"Define settings in case of interacting with the real (bebop) drone.\")\n",
    "parser.add_argument(\"--evaluate\", action='store_true', help=\"Just evaluate the network without training.\")\n",
    "parser.add_argument(\"--random_learning_rate\", action='store_true', help=\"Use sampled learning rate from UL(10**-2, 1)\")\n",
    "parser.add_argument(\"--plot_depth\", action='store_true', help=\"Specify whether the depth predictions is saved as images.\")\n",
    "\n",
    "# ===========================\n",
    "#   Data Parameters\n",
    "# ===========================\n",
    "# parser.add_argument(\"--hdf5\", action='store_true', help=\"Define wether dataset is hdf5 type.\")\n",
    "parser.add_argument(\"--load_data_in_ram\", action='store_true', help=\"Define wether the dataset is preloaded into RAM.\")\n",
    "parser.add_argument(\"--dataset\", default=\"esatv3_expert_500\", type=str, help=\"pick the dataset in data_root from which your movies can be found.\")\n",
    "parser.add_argument(\"--data_root\", default=\"pilot_data/\",type=str, help=\"Define the root folder of the different datasets.\")\n",
    "parser.add_argument(\"--num_threads\", default=4, type=int, help=\"The number of threads for loading one minibatch.\")\n",
    "parser.add_argument(\"--control_file\", default='control_info.txt', type=str, help=\"Define the name of the file with the action labels.\")\n",
    "parser.add_argument(\"--depth_directory\", default='Depth', type=str, help=\"Define the name of the directory containing the depth images: Depth or Depth_predicted.\")\n",
    "parser.add_argument(\"--subsample\", default=1, type=int, help=\"Subsample data over time: e.g. subsample 2 to get from 20fps to 10fps.\")\n",
    "parser.add_argument(\"--normalized_output\", action='store_true', help=\"Try to fill a batch with different actions [-1, 0, 1].\")\n",
    "parser.add_argument(\"--shifted_input\", action='store_true', help=\"Shift data from range 0,1 to -0.5,0.5\")\n",
    "parser.add_argument(\"--scaled_input\", action='store_true', help=\"Scale the input to 0 mean and 1 std.\")\n",
    "parser.add_argument('--scale_means', default=[0.42, 0.46, 0.5],nargs='+', help=\"Means used for scaling the input around 0\")\n",
    "parser.add_argument('--scale_stds', default=[0.218, 0.239, 0.2575],nargs='+', help=\"Stds used for scaling the input around 0\")\n",
    "parser.add_argument(\"--time_length\", default=10, type=int, help=\"In case of LSTM network, how long in time is network unrolled for training.\")\n",
    "parser.add_argument(\"--sliding_tbptt\", action='store_true', help=\"In case of LSTM network, slide over batches of data rather than sample randomly.\")\n",
    "parser.add_argument(\"--sliding_step_size\", default=1, type=int, help=\"In case of LSTM network and sliding_tbptt, define the time steps between two consecutive training batches.\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#   Model Parameters\n",
    "# ===========================\n",
    "parser.add_argument(\"--depth_multiplier\",default=0.25,type=float, help= \"Define the depth of the network in case of mobilenet.\")\n",
    "parser.add_argument(\"--network\",default='tiny_net',type=str, help=\"Define the type of network: mobile, mobile_nfc, alex, squeeze, ...\")\n",
    "# parser.add_argument(\"--output_size\",default=[55,74],type=int, nargs=2, help=\"Define the output size of the depth frame: 55x74 [drone], 1x26 [turtle], only used in case of depth_q_net.\")\n",
    "parser.add_argument(\"--pretrained\", action='store_true',help=\"Specify whether the network should be loaded with imagenet pretrained features.\")\n",
    "parser.add_argument(\"--feature_extract\", action='store_true',help=\"In case of feature extract, the model feature extraction part of the network won't be trained.\")\n",
    "# parser.add_argument(\"--n_fc\", action='store_true',help=\"In case of True, prelogit features are concatenated before feeding to the fully connected layers.\")\n",
    "parser.add_argument(\"--n_frames\",default=5,type=int,help=\"Specify the amount of frames concatenated in case of n_fc like mobile_nfc.\")\n",
    "parser.add_argument(\"--auxiliary_depth\", action='store_true',help=\"Specify whether a depth map is predicted.\")\n",
    "parser.add_argument(\"--discrete\", action='store_true',help=\"Specify whether the output action space is discrete.\")\n",
    "parser.add_argument(\"--action_quantity\",default=3, type=int, help=\"Define the number of actions in the output layer.\")\n",
    "\n",
    "# INITIALIZATION\n",
    "parser.add_argument(\"--checkpoint_path\",default='', type=str, help=\"Specify the directory of the checkpoint of the earlier trained model.\")\n",
    "parser.add_argument(\"--continue_training\",action='store_true', help=\"Continue training of the prediction layers. If false, initialize the prediction layers randomly.\")\n",
    "# parser.add_argument(\"--scratch\", action='store_true', help=\"Initialize full network randomly.\")\n",
    "\n",
    "# TRAINING\n",
    "\n",
    "parser.add_argument(\"--il_weight\", default=1.0, type=float, help=\"Define the weight of the Imitation Learning Loss in comparison to the Reinforcement Learning Loss.\")\n",
    "parser.add_argument(\"--depth_weight\", default=1.0, type=float, help=\"Define the weight applied to the depth values in the loss relative to the control loss.\")\n",
    "parser.add_argument(\"--control_weight\", default=1.0, type=float, help=\"Define the weight applied to the control loss.\")\n",
    "parser.add_argument(\"--weight_decay\",default=0.0,type=float, help= \"Weight decay of inception network\")\n",
    "parser.add_argument(\"--init_scale\", default=0.0005, type=float, help= \"Std of uniform initialization\")\n",
    "parser.add_argument(\"--grad_mul_weight\", default=0.001, type=float, help=\"Specify the amount the gradients of prediction layers.\")\n",
    "parser.add_argument(\"--dropout\", default=0.5, type=float, help=\"Specify the probability of dropout to keep the activation.\")\n",
    "# parser.add_argument(\"--hidden_size\", default=100, type=float, help=\"Specify the probability of dropout to keep the activation.\")\n",
    "\n",
    "parser.add_argument(\"--min_depth\", default=0.0, type=float, help=\"clip depth loss with weigths to focus on correct depth range.\")\n",
    "parser.add_argument(\"--max_depth\", default=5.0, type=float, help=\"clip depth loss with weigths to focus on correct depth range.\")\n",
    "parser.add_argument(\"--optimizer\", default='SGD', type=str, help=\"Specify optimizer, options: Adadelta, SGD\")\n",
    "parser.add_argument(\"--no_batchnorm_learning\",action='store_false', help=\"In case of no batchnorm learning, are the batch normalization params (alphas and betas) not further adjusted.\")\n",
    "parser.add_argument(\"--initializer\",default='xavier',type=str, help=\"Define the initializer: xavier or uniform [-init_scale, init_scale]\")\n",
    "\n",
    "parser.add_argument(\"--loss\",default='MSE',type=str, help=\"Define the loss: MSE, CrossEntropy\")\n",
    "\n",
    "# parser.add_argument(\"--max_loss\", default=100, type=float, help= \"Define the maximum loss before it is clipped.\")\n",
    "# parser.add_argument(\"--clip_loss_to_max\",action='store_true', help=\"Over time, allow only smaller losses by clipping the maximum allowed loss to the lowest maximum loss.\")\n",
    "\n",
    "# ===========================\n",
    "#   Replay Parameters\n",
    "# ===========================\n",
    "\n",
    "parser.add_argument(\"--replay_priority\", default='no', type=str, help=\"Define which type of weights should be used when sampling from replay buffer: no, uniform_action, uniform_collision, td_error, state/action/target_variance, random_action\")\n",
    "parser.add_argument(\"--prioritized_keeping\", action='store_true', help=\"In case of True, the replay buffer only keeps replay data that is most likely to be sampled.\")\n",
    "parser.add_argument(\"--hard_replay_buffer\", action='store_true', help=\"Add a replaybuffer with the hardest examples (according to the loss).\")\n",
    "parser.add_argument(\"--hard_batch_size\", default=100, type=int, help=\"Define the amount of data in one batch coming from a hard replay buffer.\")\n",
    "\n",
    "# ===========================\n",
    "#   Rosinterface Parameters\n",
    "# ===========================\n",
    "parser.add_argument(\"--online\", action='store_true', help=\"Training/evaluating online in simulation.\")\n",
    "parser.add_argument(\"--buffer_size\", default=1000, type=int, help=\"Define the number of experiences saved in the buffer.\")\n",
    "parser.add_argument(\"--ou_theta\", default=0.05, type=float, help= \"Theta is the pull back force of the OU Noise.\")\n",
    "parser.add_argument(\"--noise\", default='ou', type=str, help=\"Define whether the noise is temporally correlated (ou) or uniformly distributed (uni).\")\n",
    "parser.add_argument(\"--sigma_z\", default=0.0, type=float, help= \"sigma_z is the amount of noise in the z direction.\")\n",
    "parser.add_argument(\"--sigma_x\", default=0.0, type=float, help= \"sigma_x is the amount of noise in the forward speed.\")\n",
    "parser.add_argument(\"--sigma_y\", default=0.0, type=float, help= \"sigma_y is the amount of noise in the y direction.\")\n",
    "parser.add_argument(\"--sigma_yaw\", default=0.0, type=float, help= \"sigma_yaw is the amount of noise added to the steering angle.\")\n",
    "parser.add_argument(\"--speed\", default=1.3, type=float, help= \"Define the forward speed of the quadrotor.\")\n",
    "parser.add_argument(\"--turn_speed\", default=0.5, type=float, help= \"Define the forward speed while turning.\")\n",
    "parser.add_argument(\"--alpha\",default=0., type=float, help=\"Policy mixing: choose with a binomial probability of alpha for the experts policy instead of the DNN policy..\")\n",
    "parser.add_argument(\"--epsilon\",default=0, type=float, help=\"Apply epsilon-greedy policy for exploration.\")\n",
    "parser.add_argument(\"--epsilon_decay\", default=0.0, type=float, help=\"Decay the epsilon exploration over time with a slow decay rate of 1/10.\")\n",
    "\n",
    "parser.add_argument(\"--stochastic\", action='store_true', help=\"Used to make discrete actions more continuous by sampling gaussian around this value, with std 0.5.\")\n",
    "\n",
    "parser.add_argument(\"--prefill\", action='store_true', help=\"Fill the replay buffer first with random (epsilon 1) flying behavior before training.\")\n",
    "parser.add_argument(\"--gradient_steps\", default=1, type=int, help=\"Define the number of batches or gradient steps are taken between 2 runs.\")\n",
    "# parser.add_argument(\"--empty_buffer\", action='store_true', help=\"Empty buffer after each rollout.\")\n",
    "parser.add_argument(\"--buffer_update_rule\", default='nothing',type=str, help=\"nothing: FIFO buffer. empty: empty buffer after each training step. TODO: hard: drop certain partition of recent frames and keep only hardest.\")\n",
    "parser.add_argument(\"--buffer_hard_ratio\", default=1,type=float, help=\"if buffer_update_rule == hard, arange this ratio of the buffer's samples according to how hard they are and drop the rest, to be filled with recent frames.\")\n",
    "\n",
    "parser.add_argument(\"--max_batch_size\", default=-1, type=int, help=\"Define the max size of the batch (only if batch_size is -1).\")\n",
    "parser.add_argument(\"--recovery_compensation\", default=1, type=float, help=\"Define amount the neural network should compensate for the to-be-recovered movement.\")\n",
    "\n",
    "# parser.add_argument(\"--dont_show_depth\",action='store_true', help=\"Publish the predicted horizontal depth array to topic ./depth_prection so show_depth can visualize this in another node.\")\n",
    "\n",
    "parser.add_argument(\"--field_of_view\", default=104, type=int, help=\"The field of view of the camera cuts the depth scan in the range visible for the camera. Value should be even. Normal: 72 (-36:36), Wide-Angle: 120 (-60:60)\")\n",
    "parser.add_argument(\"--smooth_scan\", default=4, type=int, help=\"The 360degrees scan has a lot of noise and is therefore smoothed out over 4 neighboring scan readings\")\n",
    "\n",
    "parser.add_argument(\"--pause_simulator\", action='store_true', help=\"Pause simulator during frame processing, making discrete steps.\")\n",
    "parser.add_argument(\"--export_buffer\", action='store_true', help=\"Save the replaybuffer as dataset after each run.\")\n",
    "parser.add_argument(\"--no_training\", action='store_true', help=\"avoid saving to the replay buffer and taking gradient steps.\")\n",
    "\n",
    "parser.add_argument(\"--horizon\", default=0, type=int, help=\"Define the number steps back before collision, the collision label is applied to. \")\n",
    "parser.add_argument(\"--save_every_num_epochs\", default=1000, type=int, help=\"Define after how many epochs a model should be saved while training online.\")\n",
    "print(\"[main.py] Found {0} cuda devices available.\".format(torch.cuda.device_count()))\n",
    "\n",
    "try:\n",
    "    FLAGS, others = parser.parse_known_args()\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[tools] Load configuration from: ', '/esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_nfc_net_3/1/seed_0')\n",
      "set: action_bound 1.0\n",
      "set: auxiliary_depth False\n",
      "set: depth_multiplier 0.25\n",
      "set: discrete True\n",
      "set: n_frames 3\n",
      "set: network tiny_nfc_net\n",
      "set: scaled_input False\n",
      "set: shifted_input True\n",
      "set: speed 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(action_bound=1.0, action_dim=1.0, action_quantity=3, alpha=0.0, auxiliary_depth=False, batch_size=64, buffer_hard_ratio=1, buffer_size=1000, buffer_update_rule='nothing', calculate_importance_weights=False, checkpoint_path='/esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_nfc_net_3/1/seed_0', clip=1, continue_training=True, control_file='control_info.txt', control_weight=1.0, create_scratch_checkpoint=False, data_root='pilot_data/', dataset='esatv3_expert_500', depth_directory='Depth', depth_multiplier=0.25, depth_weight=1.0, device='gpu', discrete=True, dropout=0.5, epsilon=0, epsilon_decay=0.0, evaluate=False, export_buffer=False, feature_extract=False, field_of_view=104, grad_mul_weight=0.001, gradient_steps=1, hard_batch_size=100, hard_replay_buffer=False, histogram_of_activations=False, histogram_of_weights=False, horizon=0, il_weight=1.0, init_scale=0.0005, initializer='xavier', learning_rate=0.1, lifelonglearning=False, lll_weight=1, load_config=False, load_data_in_ram=False, log_tag='testing', loss='CrossEntropy', max_batch_size=-1, max_depth=5.0, max_episodes=1000, min_depth=0.0, n_frames=3, network='tiny_nfc_net', no_batchnorm_learning=True, no_training=False, noise='ou', normalized_output=False, num_threads=4, online=False, optimizer='SGD', ou_theta=0.05, owr=False, pause_simulator=False, plot_depth=False, prefill=False, pretrained=False, prioritized_keeping=False, random_learning_rate=False, random_seed=123, real=False, recovery_compensation=1, replay_priority='no', save_every_num_epochs=1000, scale_means=[0.42, 0.46, 0.5], scale_stds=[0.218, 0.239, 0.2575], scaled_input=False, shifted_input=True, sigma_x=0.0, sigma_y=0.0, sigma_yaw=0.0, sigma_z=0.0, sliding_step_size=1, sliding_tbptt=False, smooth_scan=4, speed=0.8, stochastic=False, subsample=1, summary_dir='tensorflow/log/', tensorboard=False, testing=False, time_length=10, turn_speed=0.5, update_importance_weights=False, verbose=True, visualize_activations=False, visualize_control_activation_maps=False, visualize_deep_dream_of_output=False, visualize_saliency_of_output=False, weight_decay=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings: Adjust FLAGS namespace for any specific network\n",
    "FLAGS.discrete=True\n",
    "# FLAGS.network='alex_net'\n",
    "# FLAGS.checkpoint_path='/esat/opal/kkelchte/docker_home/tensorflow/log/alex_net/esatv3_expert_20K/01/seed_0'\n",
    "# FLAGS.network='tiny_net'\n",
    "# FLAGS.checkpoint_path='/esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_net/esatv3_expert_200K/1/seed_0'\n",
    "# FLAGS.network='tiny_3d_net'\n",
    "# FLAGS.checkpoint_path='/esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_3d_net_3/1/seed_0'\n",
    "FLAGS.network='tiny_3d_net'\n",
    "FLAGS.checkpoint_path='/esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_nfc_net_3/1/seed_0'\n",
    "FLAGS.continue_training=True\n",
    "FLAGS.loss='CrossEntropy'\n",
    "tools.load_config(FLAGS, FLAGS.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model.py]: Divided 3 discrete actions over [-1.0, 0.0, 1.0] with boundaries [-0.5, 0.5].\n",
      "[model] Total number of trainable parameters: 2403313\n",
      "[model]: loaded model from /esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_nfc_net_3/1/seed_0 at epoch: 10000\n",
      "[model]: loaded optimizer parameters from /esat/opal/kkelchte/docker_home/tensorflow/log/log_neural_architectures/tiny_nfc_net_3/1/seed_0\n"
     ]
    }
   ],
   "source": [
    "model=Model(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] 00000_esatv3_500\n",
      "[data] 00003_esatv3\n",
      "[data] 00001_esatv3\n"
     ]
    }
   ],
   "source": [
    "data.prepare_data(FLAGS, model.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] loading train inputs: 0/1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/visics/kkelchte/tensorflow_1.8/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tools] calculate_importance_weights\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 4 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0dde6c0729f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportance_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_importance_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neuron'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/esat/opal/kkelchte/docker_home/tensorflow/pytorch_pilot/pilot/tools.pyc\u001b[0m in \u001b[0;36mcalculate_importance_weights\u001b[0;34m(model, input_images, level)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# forward pass of one image through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;31m# backward pass from the 2-norm of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/users/visics/kkelchte/tensorflow_1.8/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/esat/opal/kkelchte/docker_home/tensorflow/pytorch_pilot/pilot/models/tiny_nfc_net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train, verbose)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# first: rearrange data from BxTxCxHxW to BTxCxHxW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size: {0}, timesteps: {1}, C: {2}, H: {3}, W: {4}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 4 values to unpack"
     ]
    }
   ],
   "source": [
    "importance_weights=tools.calculate_importance_weights(model, data.get_all_inputs('train'), level='neuron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(importance_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for each layer the percentage of zero weights ~ 'free space'\n",
    "freespace=[]\n",
    "occupied=[]\n",
    "for index, iw in enumerate(importance_weights):\n",
    "    # ignore the biases\n",
    "    if len(iw.shape)==1: continue\n",
    "    iw=iw.flatten()\n",
    "    assert(len(iw[iw==0])+len(iw[iw!=0])==len(iw))\n",
    "    freespace.append(float(len(iw[iw==0]))/len(iw))\n",
    "    occupied.append(float(len(iw[iw!=0]))/len(iw))\n",
    "\n",
    "    \n",
    "plt.bar(range(len(occupied)),100)\n",
    "plt.bar(range(len(occupied)),[o*100 for o in occupied])\n",
    "for i,v in enumerate(occupied):\n",
    "    plt.text(i-0.25, 5, \"{0:d}%\".format(int(v*100)))\n",
    "\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Proportion')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FLAGS.checkpoint_path+'/freespace_interactively.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importance_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-769a8a2f0d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# histogram for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportance_weights\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'num_layers:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'importance_weights' is not defined"
     ]
    }
   ],
   "source": [
    "# histogram for each layer\n",
    "num_layers=sum([1 for iw in importance_weights if len(iw.shape) > 1])\n",
    "print 'num_layers:',num_layers\n",
    "f, axes = plt.subplots(num_layers, 1, figsize=(5,3*num_layers), sharex=True)\n",
    "index=0\n",
    "for iw in importance_weights:\n",
    "    if len(iw.shape)==1: continue\n",
    "    axes[index].set_title('Layer {0}'.format(index))\n",
    "    axes[index].hist(iw.flatten(), bins=50)\n",
    "    index+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
