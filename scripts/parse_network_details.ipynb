{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import numpy as np\n",
    "import sys, os, os.path\n",
    "import subprocess\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import skimage.io as sio\n",
    "import skimage.transform as sm\n",
    "\n",
    "from models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/esat/opal/kkelchte/docker_home/tensorflow/pytorch_pilot/pilot/models/tiny_nfc_net.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_nfc_net.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "network='tiny_nfc_net'\n",
    "# network='tiny_net'\n",
    "# device='cpu'\n",
    "device='cuda:0'\n",
    "net = eval(network).Net(3, n_frames=3).to(device)\n",
    "# initialize randomly\n",
    "for p in net.parameters():\n",
    "    nn.init.normal_(p,0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(6, 6), stride=(3, 3))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(10, 20, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (3): ReLU(inplace)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=24000, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature layers: 0, decision layers: 0, parameters: 24583009\n",
      "\n",
      "\n",
      "Mon Apr 15 13:52:43 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| 37%   62C    P2    63W / 250W |   1234MiB / 12187MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1344      G   /usr/libexec/Xorg                            273MiB |\n",
      "|    0     21077      G   /usr/bin/kwin_x11                             73MiB |\n",
      "|    0     21085      G   /usr/bin/krunner                               2MiB |\n",
      "|    0     21087      G   /usr/bin/plasmashell                          55MiB |\n",
      "|    0     27370      G   /usr/lib64/firefox/firefox                     2MiB |\n",
      "|    0     29701      C   ...ics/kkelchte/tensorflow_1.8/bin/python2   821MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list trainable variables + GPU size + feature layers + decision layers\n",
    "params=0\n",
    "for p in net.parameters():\n",
    "#     print p.shape\n",
    "    p_values=1\n",
    "    for d in list(p.shape[:]):\n",
    "        p_values*=d\n",
    "    params+=p_values\n",
    "    \n",
    "feature_layers, decision_layers=0,0\n",
    "# for l in net.features:\n",
    "#     if 'Conv' in str(l) or 'Linear' in str(l): \n",
    "#         feature_layers+=1\n",
    "# for l in net.network.classifier:\n",
    "#     if 'Conv' in str(l) or 'Linear' in str(l): \n",
    "#         decision_layers+=1\n",
    "print(\"feature layers: {0}, decision layers: {1}, parameters: {2}\".format(feature_layers, \n",
    "                                                                          decision_layers, \n",
    "                                                                          params))\n",
    "print(\"\\n\")\n",
    "nvidia=subprocess.check_output([\"nvidia-smi\"])\n",
    "print nvidia\n",
    "\n",
    "# print net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/visics/kkelchte/tensorflow_1.8/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "# load one run of esatv3\n",
    "run_dir='/esat/opal/kkelchte/docker_home/pilot_data/esatv3_expert/00000_esatv3/RGB'\n",
    "images=[run_dir+'/'+im for im in sorted(os.listdir(run_dir)) if im.endswith('jpg')]\n",
    "data=[]\n",
    "im_size=net.default_image_size\n",
    "for img_file in images[:100]:\n",
    "    img = sio.imread(img_file)    \n",
    "    img = np.swapaxes(img,1,2)\n",
    "    img = np.swapaxes(img,0,1)\n",
    "    scale_height = int(np.floor(img.shape[1]/im_size[1]))\n",
    "    scale_width = int(np.floor(img.shape[2]/im_size[2]))\n",
    "    img = img[:,::scale_height,::scale_width]\n",
    "    img = sm.resize(img,im_size,mode='constant').astype(np.float16)\n",
    "    img -= 0.5\n",
    "    assert len(img) != 0, '[data] Loading image failed: {}'.format(img_file)\n",
    "    data.append(img)\n",
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 4 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4c6b659bfba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mload_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpredict_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m print(\"load: {0}({1}), prediction: {2}({3})\".format(np.mean(load_time),\n",
      "\u001b[0;32m/esat/opal/kkelchte/docker_home/tensorflow/pytorch_pilot/pilot/models/tiny_nfc_net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, train, verbose)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# first: rearrange data from BxTxCxHxW to BTxCxHxW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size: {0}, timesteps: {1}, C: {2}, H: {3}, W: {4}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 4 values to unpack"
     ]
    }
   ],
   "source": [
    "# evaluate model (without autograd) and measure FPS\n",
    "load_time=[]\n",
    "predict_time=[]\n",
    "for i in range(data.shape[0]):\n",
    "    if i%100 == 0: print(\"Frame {0}/{1}\".format(i,data.shape[0]))\n",
    "    stime=time.time()\n",
    "    inputs=torch.from_numpy(np.expand_dims(data[0],0)).type(torch.FloatTensor).to(device)\n",
    "    load_time.append(time.time()-stime)\n",
    "    stime=time.time()\n",
    "    predictions = net.forward(inputs, train=False)\n",
    "    predict_time.append(time.time()-stime)\n",
    "print(\"load: {0}({1}), prediction: {2}({3})\".format(np.mean(load_time),\n",
    "                                                                          np.std(load_time),\n",
    "                                                                          np.mean(predict_time),\n",
    "                                                                          np.std(predict_time)))\n",
    "print(\"speed: {0}\".format(1/np.mean(predict_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
