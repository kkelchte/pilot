{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/esat/opal/kkelchte/docker_home/tensorflow/q-learning/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pilot.model import Model\n",
    "from pilot import data\n",
    "import tensorflow as tf\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Main pilot that can train or evaluate online or offline from a dataset.')\n",
    "  \n",
    "# ==========================\n",
    "#   Training Parameters\n",
    "# ==========================\n",
    "parser.add_argument(\"--testing\", action='store_true', help=\"In case we're only testing, the model is tested on the test.txt files and not trained.\")\n",
    "parser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Start learning rate.\")\n",
    "parser.add_argument(\"--batch_size\",default=64,type=int,help=\"Define the size of minibatches.\")\n",
    "\n",
    "# ==========================\n",
    "#   Offline Parameters\n",
    "# ==========================\n",
    "parser.add_argument(\"--offline\", action='store_false', help=\"Training from an offline dataset.\")\n",
    "parser.add_argument(\"--max_episodes\",default=1000,type=int,help=\"The maximum number of episodes (~runs through all the training data.)\")\n",
    "\n",
    "# ===========================\n",
    "#   Utility Parameters\n",
    "# ===========================\n",
    "# Print output of ros verbose or not\n",
    "parser.add_argument(\"--load_config\", action='store_true',help=\"Load flags from the configuration file found in the checkpoint path.\")\n",
    "parser.add_argument(\"--verbose\", action='store_false', help=\"Print output of ros verbose or not.\")\n",
    "parser.add_argument(\"--summary_dir\", default='tensorflow/log/', type=str, help=\"Choose the directory to which tensorflow should save the summaries.\")\n",
    "parser.add_argument(\"--log_tag\", default='testing', type=str, help=\"Add log_tag to overcome overwriting of other log files.\")\n",
    "parser.add_argument(\"--device\", default='/gpu:0', type=str, help= \"Choose to run on gpu or cpu: /cpu:0 or /gpu:0\")\n",
    "parser.add_argument(\"--random_seed\", default=123, type=int, help=\"Set the random seed to get similar examples.\")\n",
    "parser.add_argument(\"--owr\", action='store_true', help=\"Overwrite existing logfolder when it is not testing.\")\n",
    "parser.add_argument(\"--action_bound\", default=1.0, type=float, help= \"Define between what bounds the actions can go. Default: [-1:1].\")\n",
    "parser.add_argument(\"--real\", action='store_true', help=\"Define settings in case of interacting with the real (bebop) drone.\")\n",
    "parser.add_argument(\"--evaluate\", action='store_true', help=\"Just evaluate the network without training.\")\n",
    "parser.add_argument(\"--random_learning_rate\", action='store_true', help=\"Use sampled learning rate from UL(10**-2, 1)\")\n",
    "parser.add_argument(\"--plot_depth\", action='store_true', help=\"Specify whether the depth predictions is saved as images.\")\n",
    "\n",
    "# ===========================\n",
    "#   Data Parameters\n",
    "# ===========================\n",
    "parser.add_argument(\"--normalize_data\", action='store_true', help=\"Define wether the collision tags 0 or 1 are normalized in a batch. Only relevant for coll q net.\")\n",
    "parser.add_argument(\"--dataset\", default=\"canyon_rl_turtle\", type=str, help=\"pick the dataset in data_root from which your movies can be found.\")\n",
    "parser.add_argument(\"--data_root\", default=\"~/pilot_data\",type=str, help=\"Define the root folder of the different datasets.\")\n",
    "parser.add_argument(\"--num_threads\", default=4, type=int, help=\"The number of threads for loading one minibatch.\")\n",
    "parser.add_argument(\"--collision_file\", default='collision_info.txt', type=str, help=\"Define the name of the file with the collision labels.\")\n",
    "parser.add_argument(\"--control_file\", default='control_info.txt', type=str, help=\"Define the name of the file with the action labels.\")\n",
    "\n",
    "# ===========================\n",
    "#   Model Parameters\n",
    "# ===========================\n",
    "parser.add_argument(\"--depth_multiplier\",default=0.25,type=float, help= \"Define the depth of the network in case of mobilenet.\")\n",
    "parser.add_argument(\"--network\",default='coll_q_net',type=str, help=\"Define the type of network: depth_q_net, coll_q_net.\")\n",
    "# parser.add_argument(\"--n_fc\", action='store_true',help=\"In case of True, prelogit features are concatenated before feeding to the fully connected layers.\")\n",
    "# parser.add_argument(\"--n_frames\",default=3,type=int,help=\"Specify the amount of frames concatenated in case of n_fc.\")\n",
    "\n",
    "# INITIALIZATION\n",
    "parser.add_argument(\"--checkpoint_path\",default='mobilenet_025', type=str, help=\"Specify the directory of the checkpoint of the earlier trained model.\")\n",
    "parser.add_argument(\"--continue_training\",action='store_true', help=\"Continue training of the prediction layers. If false, initialize the prediction layers randomly.\")\n",
    "parser.add_argument(\"--scratch\", action='store_true', help=\"Initialize full network randomly.\")\n",
    "\n",
    "# TRAINING\n",
    "parser.add_argument(\"--weight_decay\",default=0.00004,type=float, help= \"Weight decay of inception network\")\n",
    "parser.add_argument(\"--init_scale\", default=0.0005, type=float, help= \"Std of uniform initialization\")\n",
    "parser.add_argument(\"--grad_mul_weight\", default=0, type=float, help=\"Specify the amount the gradients of prediction layers.\")\n",
    "parser.add_argument(\"--dropout_keep_prob\", default=0.5, type=float, help=\"Specify the probability of dropout to keep the activation.\")\n",
    "parser.add_argument(\"--clip_grad\", default=0, type=int, help=\"Specify the max gradient norm: default 0 is no clipping, recommended 4.\")\n",
    "parser.add_argument(\"--min_depth\", default=0.001, type=float, help=\"clip depth loss with weigths to focus on correct depth range.\")\n",
    "parser.add_argument(\"--max_depth\", default=2.0, type=float, help=\"clip depth loss with weigths to focus on correct depth range.\")\n",
    "parser.add_argument(\"--optimizer\", default='adadelta', type=str, help=\"Specify optimizer, options: adam, adadelta, gradientdescent, rmsprop\")\n",
    "# parser.add_argument(\"--no_batchnorm_learning\",action='store_false', help=\"In case of no batchnorm learning, are the batch normalization params (alphas and betas) not further adjusted.\")\n",
    "parser.add_argument(\"--initializer\",default='xavier',type=str, help=\"Define the initializer: xavier or uniform [-init_scale, init_scale]\")\n",
    "\n",
    "parser.add_argument(\"--loss\",default='mse',type=str, help=\"Define the loss: mse, huber or absolute\")\n",
    "\n",
    "# ===========================\n",
    "#   Replay Parameters\n",
    "# ===========================\n",
    "\n",
    "parser.add_argument(\"--normalized_replay\", action='store_true', help=\"Make labels / actions equally likely for the coll / depth q net.\")\n",
    "\n",
    "# ===========================\n",
    "#   Rosinterface Parameters\n",
    "# ===========================\n",
    "parser.add_argument(\"--buffer_size\", default=1000, type=int, help=\"Define the number of experiences saved in the buffer.\")\n",
    "parser.add_argument(\"--ou_theta\", default=0.05, type=float, help= \"Theta is the pull back force of the OU Noise.\")\n",
    "parser.add_argument(\"--noise\", default='ou', type=str, help=\"Define whether the noise is temporally correlated (ou) or uniformly distributed (uni).\")\n",
    "parser.add_argument(\"--sigma_z\", default=0.0, type=float, help= \"sigma_z is the amount of noise in the z direction.\")\n",
    "parser.add_argument(\"--sigma_x\", default=0.0, type=float, help= \"sigma_x is the amount of noise in the forward speed.\")\n",
    "parser.add_argument(\"--sigma_y\", default=0.0, type=float, help= \"sigma_y is the amount of noise in the y direction.\")\n",
    "parser.add_argument(\"--sigma_yaw\", default=0.0, type=float, help= \"sigma_yaw is the amount of noise added to the steering angle.\")\n",
    "parser.add_argument(\"--speed\", default=0.5, type=float, help= \"Define the forward speed of the quadrotor.\")\n",
    "parser.add_argument(\"--epsilon\",default=0, type=float, help=\"Apply epsilon-greedy policy for exploration.\")\n",
    "parser.add_argument(\"--epsilon_decay\", default=0.0, type=float, help=\"Decay the epsilon exploration over time with a slow decay rate of 1/10.\")\n",
    "parser.add_argument(\"--prefill\", action='store_true', help=\"Fill the replay buffer first with random (epsilon 1) flying behavior before training.\")\n",
    "\n",
    "parser.add_argument(\"--action_amplitude\", default=1, type=int, help=\"Define the action that is used as input to estimate Q value.\")\n",
    "parser.add_argument(\"--action_quantity\",default=3, type=int, help=\"Define the number of actions used at the forward pass to evaluate a state.\")\n",
    "parser.add_argument(\"--action_smoothing\",action='store_true', help=\"Define whether the actions should be sampled uniformly within the bin to represent better the continuous actions space.\")\n",
    "parser.add_argument(\"--action_normalization\",action='store_true', help=\"Normalize action space from -1:1 to 0:1 avoiding gradients to cancel out.\")\n",
    "\n",
    "parser.add_argument(\"--off_policy\",action='store_true', help=\"In case the network is off_policy, the control is published on supervised_vel instead of cmd_vel.\")\n",
    "parser.add_argument(\"--show_depth\",action='store_false', help=\"Publish the predicted horizontal depth array to topic ./depth_prection so show_depth can visualize this in another node.\")\n",
    "\n",
    "parser.add_argument(\"--grad_steps\", default=10, type=int, help=\"Define the number of batches or gradient steps are taken between 2 runs.\")\n",
    "parser.add_argument(\n",
    "        '-f',\n",
    "        '--file',\n",
    "        help='Path for input file. First line should contain number of lines to search in'\n",
    "    )\n",
    "FLAGS=parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct parameters for model you want to test\n",
    "FLAGS.network='depth_q_net'\n",
    "FLAGS.checkpoint_path='off_depth_turtle/turtle_depth_abs_clip0001-2_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "action_dim = 1\n",
    "\n",
    "config=tf.ConfigProto(allow_soft_placement=True)\n",
    "# config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "# Keep it at true, in online fashion with singularity (not condor) on qayd (not laptop) resolves this in a Cudnn Error\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "# config.gpu_options.allow_growth = False\n",
    "sess = tf.Session(config=config)\n",
    "model = Model(FLAGS, sess, action_dim)\n",
    "writer = tf.summary.FileWriter(FLAGS.summary_dir+FLAGS.log_tag, sess.graph)\n",
    "model.writer = writer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
